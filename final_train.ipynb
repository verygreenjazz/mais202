{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM-axLZNMl0X",
        "outputId": "609435cf-c237-470d-bd15-d1fceb9ea02a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 90.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "from torchvision.transforms import v2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 30)\n",
        "# Load the initially trained model from initial_train.ipynb (optional)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/MAIS202/initial_train_resnet18_mnist.pth\"))\n",
        "\n",
        "# Set the model to training mode and use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Transform images to 224x224 and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # changing this resulting in the initial loss falling from\n",
        "                                                                                    # ~50 to 0.0013!!\n",
        "])\n",
        "\n",
        "\n",
        "# Load the Recyclable and House Waste dataset\n",
        "\n",
        "class WasteDataset():\n",
        "    def __init__(self, split, root_dir=\"/content/drive/MyDrive/MAIS202/dataset/images/images\", transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classDict = {0 : 'aerosol_cans',\n",
        "                            1 : 'aluminum_food_cans',\n",
        "                            2 : 'aluminum_soda_cans',\n",
        "                            3 : 'cardboard_boxes',\n",
        "                            4 : 'cardboard_packaging',\n",
        "                            5 : 'clothing',\n",
        "                            6 : 'coffee_grounds',\n",
        "                            7 : 'disposable_plastic_cutlery',\n",
        "                            8 : 'eggshells',\n",
        "                            9 : 'food_waste',\n",
        "                            10 : 'glass_beverage_bottles',\n",
        "                            11 : 'glass_cosmetic_containers',\n",
        "                            12 : 'glass_food_jars',\n",
        "                            13 : 'magazines',\n",
        "                            14 : 'newspaper',\n",
        "                            15 : 'office_paper',\n",
        "                            16 : 'paper_cups',\n",
        "                            17 : 'plastic_cup_lids',\n",
        "                            18 : 'plastic_detergent_bottles',\n",
        "                            19 : 'plastic_food_containers',\n",
        "                            20 : 'plastic_shopping_bags',\n",
        "                            21 : 'plastic_soda_bottles',\n",
        "                            22 : 'plastic_straws',\n",
        "                            23 : 'plastic_trash_bags',\n",
        "                            24 : 'plastic_water_bottles',\n",
        "                            25 : 'shoes',\n",
        "                            26 : 'steel_food_cans',\n",
        "                            27 : 'styrofoam_cups',\n",
        "                            28 : 'styrofoam_food_containers',\n",
        "                            29 : 'tea_bags'}\n",
        "        self.wasteDict = {\"aerosol_cans\": \"Landfill\",\n",
        "                                \"aluminum_food_cans\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"aluminum_soda_cans\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"cardboard_boxes\": \"Paper, Cardboard Recyclable\",\n",
        "                                \"cardboard_packaging\": \"Paper, Cardboard Recyclable\",\n",
        "                                \"clothing\": \"Landfill\",\n",
        "                                \"coffee_grounds\": \"Compostable\",\n",
        "                                \"disposable_plastic_cutlery\": \"Landfill\",\n",
        "                                \"eggshells\": \"Compostable\",\n",
        "                                \"food_waste\": \"Compostable\",\n",
        "                                \"glass_beverage_bottles\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"glass_cosmetic_containers\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"glass_food_jars\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"magazines\": \"Paper, Cardboard Recyclable\",\n",
        "                                \"newspaper\": \"Paper, Cardboard Recyclable\",\n",
        "                                \"office_paper\": \"Paper, Cardboard Recyclable\",\n",
        "                                \"paper_cups\": \"Paper, Cardboard Recyclable\",\n",
        "                                \"plastic_cup_lids\": \"Landfill\",\n",
        "                                \"plastic_detergent_bottles\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"plastic_food_containers\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"plastic_shopping_bags\": \"Landfill\",\n",
        "                                \"plastic_soda_bottles\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"plastic_straws\": \"Landfill\",\n",
        "                                \"plastic_trash_bags\": \"Landfill\",\n",
        "                                \"plastic_water_bottles\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"shoes\": \"Landfill\",\n",
        "                                \"steel_food_cans\": \"Plastic, Glass, Metal Recyclable\",\n",
        "                                \"styrofoam_cups\": \"Landfill\",\n",
        "                                \"styrofoam_food_containers\": \"Landfill\",\n",
        "                                \"tea_bags\": \"Compostable\",}\n",
        "\n",
        "        for i, class_name in enumerate(self.classes): # maybe change this to iterate over the labelsDict\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            for subfolder in ['default', 'real_world']:\n",
        "                subfolder_dir = os.path.join(class_dir, subfolder)\n",
        "                image_names = os.listdir(subfolder_dir)\n",
        "                random.shuffle(image_names)\n",
        "\n",
        "                if split == 'train':\n",
        "                    image_names = image_names[:int(0.05 * len(image_names))] # note!! only 5% of the dataset is used for the initial train\n",
        "                elif split == 'val':\n",
        "                    image_names = image_names[int(0.6 * len(image_names)):int(0.8 * len(image_names))]\n",
        "                else:  # split == 'test'\n",
        "                    image_names = image_names[int(0.8 * len(image_names)):]\n",
        "\n",
        "                for image_name in image_names:\n",
        "                    self.image_paths.append(os.path.join(subfolder_dir, image_name))\n",
        "                    self.labels.append(i)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = self.image_paths[index]\n",
        "        label = self.labels[index]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        data = {\n",
        "            \"image\":image,\n",
        "            \"label\":label,\n",
        "        }\n",
        "        return data\n",
        "\n",
        "\n",
        "# Prepare datasets and dataloaders\n",
        "\n",
        "train_pil_transform = v2.Compose([\n",
        "        v2.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.2),\n",
        "        v2.RandomAffine(degrees=5, translate=(0.1, 0.1),scale=(0.8,1.3),\n",
        "                        interpolation=torchvision.transforms.InterpolationMode.BILINEAR),\n",
        "        v2.Resize(size=(256, 256)),\n",
        "        v2.GaussianBlur(kernel_size=(7, 13), sigma=(0.1, 0.2)),\n",
        "        v2.PILToTensor(),\n",
        "        v2.ToDtype(torch.float32),\n",
        "        v2.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))\n",
        "    ])\n",
        "\n",
        "val_pil_transform = v2.Compose([\n",
        "    v2.Resize(size=(256, 256)),\n",
        "    v2.PILToTensor(),\n",
        "    v2.ToDtype(torch.float32),\n",
        "    v2.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "test_pil_transform = v2.Compose([\n",
        "    v2.Resize(size=(256, 256)),\n",
        "    v2.PILToTensor(),\n",
        "    v2.ToDtype(torch.float32),\n",
        "    v2.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "data_transforms = {\n",
        "    \"train\":train_pil_transform,\n",
        "    \"val\":val_pil_transform,\n",
        "    \"test\":test_pil_transform,\n",
        "}\n",
        "\n",
        "train_dataset = WasteDataset(split=\"train\", transform=data_transforms[\"train\"])\n",
        "val_dataset = WasteDataset(split=\"val\", transform=data_transforms[\"val\"])\n",
        "test_dataset = WasteDataset(split=\"test\", transform=data_transforms[\"test\"])\n",
        "\n",
        "\n",
        "\n",
        "# Load the Recyclable and House Waste dataset\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "validateloader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# translates the numerical classses outputted by the model to their original human-readable class\n",
        "classtranslater = train_dataset.classDict\n",
        "\n",
        "# sorts the human-readable class into one of McGill's 4 nonhazardous waste streams\n",
        "wastetranslater = train_dataset.wasteDict\n",
        "\n",
        "def wastesort(classInputted):\n",
        "    return wastetranslater[classtranslater[classInputted]]\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Learning rate scheduler to adjust the learning rate\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNSWQs6-7ZRp",
        "outputId": "fb24331d-5363-4ddb-ff6d-1b4500ac49b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the fine-tuned model on the test images: 62.87%\n",
            "Epoch [1/50], Loss: 0.0013\n",
            "Accuracy of the fine-tuned model on the test images: 68.63%\n",
            "Epoch [2/50], Loss: 0.0027\n",
            "Accuracy of the fine-tuned model on the test images: 70.23%\n",
            "Epoch [3/50], Loss: 0.0007\n",
            "Accuracy of the fine-tuned model on the test images: 75.90%\n",
            "Epoch [4/50], Loss: 0.0006\n",
            "Accuracy of the fine-tuned model on the test images: 75.13%\n",
            "Epoch [5/50], Loss: 0.0002\n",
            "Accuracy of the fine-tuned model on the test images: 77.53%\n",
            "Epoch [6/50], Loss: 0.0005\n",
            "Accuracy of the fine-tuned model on the test images: 73.13%\n",
            "Epoch [7/50], Loss: 0.0010\n",
            "Accuracy of the fine-tuned model on the test images: 77.73%\n",
            "Epoch [8/50], Loss: 0.0002\n",
            "Accuracy of the fine-tuned model on the test images: 79.33%\n",
            "Epoch [9/50], Loss: 0.0005\n",
            "Accuracy of the fine-tuned model on the test images: 80.00%\n",
            "Epoch [10/50], Loss: 0.0002\n",
            "Accuracy of the fine-tuned model on the test images: 80.33%\n",
            "Epoch [11/50], Loss: 0.0002\n",
            "Accuracy of the fine-tuned model on the test images: 80.33%\n",
            "Epoch [12/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 80.80%\n",
            "Epoch [13/50], Loss: 0.0002\n",
            "Accuracy of the fine-tuned model on the test images: 80.80%\n",
            "Epoch [14/50], Loss: 0.0005\n",
            "Accuracy of the fine-tuned model on the test images: 80.50%\n",
            "Epoch [15/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 80.67%\n",
            "Epoch [16/50], Loss: 0.0005\n",
            "Accuracy of the fine-tuned model on the test images: 80.83%\n",
            "Epoch [17/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 80.77%\n",
            "Epoch [18/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 80.80%\n",
            "Epoch [19/50], Loss: 0.0003\n",
            "Accuracy of the fine-tuned model on the test images: 80.83%\n",
            "Epoch [20/50], Loss: 0.0003\n",
            "Accuracy of the fine-tuned model on the test images: 81.20%\n",
            "Epoch [21/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 81.10%\n",
            "Epoch [22/50], Loss: 0.0000\n",
            "Accuracy of the fine-tuned model on the test images: 80.97%\n",
            "Epoch [23/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 81.13%\n",
            "Epoch [24/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 80.80%\n",
            "Epoch [25/50], Loss: 0.0001\n",
            "Accuracy of the fine-tuned model on the test images: 80.90%\n",
            "Epoch [26/50], Loss: 0.0003\n",
            "Accuracy of the fine-tuned model on the test images: 81.07%\n",
            "Epoch [27/50], Loss: 0.0001\n"
          ]
        }
      ],
      "source": [
        "# Fine-tuning\n",
        "num_epochs = 50\n",
        "# the number of epochs is set to 5 for the initial train\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for idx, data in enumerate(trainloader): # each entry in trainloader (each idx) is a batch of 64 images and their labels\n",
        "        images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()*images.size(0)\n",
        "        running_loss /= len(train_dataset)\n",
        "        train_losses.append(running_loss)\n",
        "\n",
        "\n",
        "    # step the scheduler after each epoch\n",
        "    scheduler.step()\n",
        "\n",
        "    # evaluating the model\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    #correctSort = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, data in enumerate(testloader): # each entry in testloader (each idx) is a batch of 64 images and their labels\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            #predictedwaste = [wastesort(val.item()) for val in predicted]\n",
        "            #labelwaste = [wastesort(val.item()) for val in labels]\n",
        "            #predictedwaste = np.array(predictedwaste)\n",
        "            #labelwaste = np.array(labelwaste)\n",
        "            #correctSort += np.sum(predictedwaste == labelwaste)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()*images.size(0)\n",
        "\n",
        "    val_loss /= len(val_dataset)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_accuracies\n",
        "\n",
        "    print(f'Accuracy of the fine-tuned model on the test images: {val_accuracy:.2f}%')\n",
        "    #print(f'Accuracy of the fine-tuned model on the task (sorting objects into their waste categories): {100 * correctSort / total:.2f}%')\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
        "\n",
        "    save_path = \"/content/drive/MyDrive/MAIS202/\"\n",
        "    torch.save(model.state_dict(), os.path.join(save_path, 'final_train_resnet18_epoch-{}.pth'.format(epoch)))\n",
        "\n",
        "\n",
        "print('Fine-tuning complete')\n",
        "\n",
        "\n",
        "\n",
        "print('Model saved')\n",
        "\n",
        "# takes 1 epoch 24 minutes to run\n",
        "# after epoch 1, results:\n",
        "# Accuracy of the fine-tuned model on the test images: 61.97%\n",
        "# Epoch [1/1], Loss: 0.0013\n",
        "# Fine-tuning complete\n",
        "# Model saved\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DV9QDEfIegtqAnV22s06omkiKO0lNBqR",
      "authorship_tag": "ABX9TyMI0ZEH/SfcwEvbcUzwRUCD"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}